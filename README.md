****ğŸ“„ Document Vector Search & Question Answering Backend (RAG)****

A backend application that enables document ingestion, semantic search, and question answering using modern Retrieval-Augmented Generation (RAG) architecture.
Users can upload documents (such as resumes), store them as vector embeddings in a PostgreSQL database, and ask natural language questions to retrieve accurate, context-aware answers.

**ğŸ” Project Overview**

Traditional keyword search fails to capture semantic meaning in documents.
This project solves that problem by:
Converting documents into vector embeddings
Storing them in a vector-enabled PostgreSQL database
Performing similarity search to retrieve relevant context
Using a Large Language Model (LLM) to generate grounded answers
This architecture is widely used in GenAI-powered enterprise applications such as document assistants, internal knowledge bases, and resume analyzers.

**âœ¨ Key Features**

ğŸ“¤ Upload documents (PDF / TXT)
âœ‚ï¸ Split documents into manageable chunks
ğŸ”¢ Generate embeddings using Azure OpenAI
ğŸ§  Store vectors using pgvector in PostgreSQL
ğŸ” Perform semantic similarity search
ğŸ¤– Answer questions using retrieved document context (RAG)
ğŸŒ REST APIs built with FastAPI
ğŸ§ª Fully testable via Postman
ğŸ” Secure handling of secrets using environment variables

**ğŸ—ï¸ System Architecture**

Client (Postman / API Consumer)
            |
            v
     FastAPI Backend
            |
            |-- Embedding Generation (Azure OpenAI)
            |
     PostgreSQL + pgvector (Aiven)
            |
     Semantic Similarity Search
            |
            v
   Context-Aware Answer Generation

**ğŸ§° Technology Stack**

Backend Framework: FastAPI
Programming Language: Python 3.10+
Vector Database: PostgreSQL + pgvector (Aiven)
Embeddings & LLM: Azure OpenAI
Database Driver: psycopg2
Document Parsing: pypdf
API Testing: Postman

ğŸ§  Why These Design Choices?
ğŸ”¹ Why PostgreSQL + pgvector?

Avoids adding a separate vector database
Uses familiar relational infrastructure
Cost-effective and production-ready
Supports cosine similarity directly inside SQL

ğŸ”¹ Why Azure OpenAI?

Enterprise-grade security and compliance
Reliable deployments with explicit model control
Ideal for production GenAI workloads

ğŸ”¹ Why FastAPI?

High performance
Automatic OpenAPI documentation
Clean separation of concerns
Widely adopted in production APIs

âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone the Repository
git clone https://github.com/<your-username>/doc-vector-backend.git
cd doc-vector-backend

2ï¸âƒ£ Create and Activate Virtual Environment
python -m venv venv
venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Configure Environment Variables

Create a .env file in the project root (do not commit this file):

# Azure OpenAI
AZURE_OPENAI_ENDPOINT=your_azure_endpoint
AZURE_OPENAI_API_KEY=your_api_key
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=your_embedding_deployment

# PostgreSQL (Aiven)
DB_HOST=hostname
DB_PORT=port
DB_NAME=database
DB_USER=username
DB_PASSWORD=password


Secrets are intentionally excluded using .gitignore.

â–¶ï¸ Running the Application

Start the FastAPI server:

uvicorn app.main:app --reload


Access API documentation at:

http://127.0.0.1:8000/docs


ğŸ”Œ API Endpoints
ğŸ“¤ Upload Document
POST /upload


**Description:**

Accepts PDF or TXT files
Extracts text
Splits content into chunks
Generates embeddings
Stores vectors in PostgreSQL

â“ Query Documents
POST /query?question=your_question


**Description:**

Converts the question into an embedding
Retrieves top matching document chunks
Sends context to LLM
Returns a grounded, natural-language answer

**ğŸ§ª Example Use Case**

Upload your resume

Ask questions such as:

â€œWhat skills do I have?â€
â€œDo I have cloud experience?â€
â€œSummarize my professional profileâ€
Receive answers based only on your document

**ğŸ” Security & Best Practices**

Secrets managed via environment variables
.env excluded from version control
GitHub Push Protection enabled
Clean commit history
No credentials stored in code

**ğŸš§ Limitations & Future Enhancements**

Frontend UI (planned)
Authentication & authorization
Metadata-based filtering
Hybrid search (keyword + vector)
Deployment to Azure App Service
Streaming responses
Support for larger document sets

**ğŸ¯ Learning Outcomes**

This project demonstrates practical experience with:
RAG architecture
Vector databases
Azure OpenAI deployments
Backend API design
Secure secret management
Real-world Git workflows
